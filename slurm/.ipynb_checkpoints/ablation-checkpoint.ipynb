{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43f2c06d-2249-46fd-bdbb-9b1f8b929aa0",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "# Set environment variables\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".99\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import jax\n",
    "# from jax import config\n",
    "# config.update('jax_enable_x64', True)\n",
    "\n",
    "# Check JAX configuration\n",
    "devices = jax.local_devices()\n",
    "print(devices)\n",
    "print(jax.default_backend())\n",
    "print(jax.devices())\n",
    "\n",
    "import sys\n",
    "# Add custom path\n",
    "sys.path.append(\"/pchem-data/meuwly/boittier/home/pycharmm_test/src\")\n",
    "\n",
    "# from model import EF\n",
    "# from loss import dipole_calc\n",
    "# from  training import train_model # from model import dipole_calc\n",
    "import jax\n",
    "import optax\n",
    "import e3x\n",
    "\n",
    "# from dcmnet.analysis import create_model_and_params\n",
    "# from data import prepare_batches, prepare_datasets\n",
    "import numpy as np\n",
    "\n",
    "from physnetjax.model import EF\n",
    "from physnetjax.loss import dipole_calc\n",
    "from  physnetjax.training import train_model # from model import dipole_calc\n",
    "from physnetjax.data import prepare_batches, prepare_datasets\n",
    "\n",
    "\n",
    "import orbax\n",
    "from orbax.checkpoint import PyTreeCheckpointer\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "# Set environment variables\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".99\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import jax\n",
    "# from jax import config\n",
    "# config.update('jax_enable_x64', True)\n",
    "\n",
    "# Check JAX configuration\n",
    "devices = jax.local_devices()\n",
    "print(devices)\n",
    "print(jax.default_backend())\n",
    "print(jax.devices())\n",
    "\n",
    "import sys\n",
    "# Add custom path\n",
    "sys.path.append(\"/pchem-data/meuwly/boittier/home/pycharmm_test/src\")\n",
    "\n",
    "# from model import EF\n",
    "# from loss import dipole_calc\n",
    "# from  training import train_model # from model import dipole_calc\n",
    "import jax\n",
    "import optax\n",
    "import e3x\n",
    "\n",
    "# from dcmnet.analysis import create_model_and_params\n",
    "# from data import prepare_batches, prepare_datasets\n",
    "import numpy as np\n",
    "\n",
    "from physnetjax.model import EF\n",
    "from physnetjax.loss import dipole_calc\n",
    "from  physnetjax.training import train_model # from model import dipole_calc\n",
    "from physnetjax.data import prepare_batches, prepare_datasets\n",
    "\n",
    "\n",
    "import orbax\n",
    "from orbax.checkpoint import PyTreeCheckpointer\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "\n",
    "from physnetjax.analysis import *\n",
    "\n",
    "import polars as pl\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "\n",
    "\n",
    "\n",
    "import struct\n",
    "\n",
    "def read_tensor(value):\n",
    "    # Assuming the content is a single 32-bit float\n",
    "    binary_content = value.tensor.tensor_content\n",
    "    try:\n",
    "        float_value = struct.unpack('f', binary_content)[0]  # 'f' is for 32-bit float\n",
    "        # print(f\"Decoded float value: {float_value}\")\n",
    "        return value.tag, float_value\n",
    "    except struct.error:\n",
    "        # print(\"Unable to decode binary content as float.\")\n",
    "         return value.tag, 0\n",
    "    \n",
    "\n",
    "\n",
    "def tensorboard_to_polars(logdir, i = 0):\n",
    "    # Read the log file\n",
    "    data = {}\n",
    "    for event in summary_iterator(str(logdir)):\n",
    "        for value in event.summary.value:\n",
    "            k,v=read_tensor(value)\n",
    "            data[k] = v\n",
    "    data[\"epoch\"] = i\n",
    "    data[\"log\"] = str(logdir)\n",
    "    if data:\n",
    "        df = pl.DataFrame(data)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No scalar data found in the logdir.\")\n",
    "        return pl.DataFrame()\n",
    "\n",
    "from pathlib import Path\n",
    "from physnetjax.utils import get_last, get_files, get_params_model\n",
    "from physnetjax.analysis import plot_stats, count_params\n",
    "# restart_dir_base = Path(\"/pchem-data/meuwly/boittier/home/pycharmm_test/ckpts\")\n",
    "# # Specify the log directory path\n",
    "# path = restart_dir_base / \"test-4ae608b9-b9f8-42e6-9292-4ff3841b9962/tfevents\" \n",
    "# files = list(path.glob(\"*\"))\n",
    "# print(files[0])\n",
    "# # Path to the TensorBoard log file\n",
    "# log_file = str(files[0])\n",
    "\n",
    "# # Convert TensorBoard logs to a Polars DataFrame\n",
    "# base_df = pl.concat([tensorboard_to_polars(str(_),i=i) for i, _ in enumerate(files) ])\n",
    "\n",
    "# # Display the first few rows\n",
    "# print(base_df.head())\n",
    "# print(base_df.columns)\n",
    "DATA_FILES = [\"/pchem-data/meuwly/boittier/home/jaxeq/notebooks/ala-esp-dip-0.npz\"]\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e4adcb8-d3ca-4bd1-a8bd-0a9d4aea1e41",
   "metadata": {},
   "source": [
    "for l in [0,1]:\n",
    "    for nres in [1,-1]:\n",
    "        for feat in [64,128]:\n",
    "            for nit in [2,4]:\n",
    "                job = f\"\"\"sbatch --export=ALL,max_degree={l},nres={nres},num_iterations={nit},features={feat},data=/pchem-data/meuwly/boittier/home/jaxeq/notebooks/ala-esp-dip-0.npz,name=cf3all,natoms=37,totalchg=0.0,ntrain=8000,nvalid=1786,nepochs=50000,batch_size=8,schedule=\"constant\" ./submit-job.sh\n",
    "                \"\"\"\n",
    "                print(job)\n",
    "                os.system(job)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2d3e6d-914d-4d52-a6d3-462a369c546d",
   "metadata": {},
   "source": [
    "for l in [0,]:\n",
    "    for nres in [1]:\n",
    "        for feat in [64]:\n",
    "            for nit in [4]:\n",
    "                job = f\"\"\"sbatch --export=ALL,max_degree={l},nres={nres},num_iterations={nit},features={feat},data=/pchem-data/meuwly/boittier/home/cf3criegee_27887.npz,name=cf3all,natoms=8,totalchg=0.0,ntrain=23887,nvalid=4000,nepochs=50000,batch_size=8,schedule=\"constant\" ./submit-job.sh\n",
    "                \"\"\"\n",
    "                print(job)\n",
    "                # os.system(job)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9734b-2666-4b9a-81fd-4a935c846f06",
   "metadata": {},
   "source": [
    "file_names = []\n",
    "ls = []\n",
    "fs = []\n",
    "nits = []\n",
    "for of in outfiles:\n",
    "    with open(of) as f:\n",
    "        lines = f.readlines(30000)\n",
    "        sel = [bytes(_, \"utf8\").decode(\"utf8\") for _ in lines if \"cf3all-\" in _]\n",
    "        sel2 = [bytes(_, \"utf8\").decode(\"utf8\") for _ in lines if \"epoch\" in _]\n",
    "        file_names.append(\"\".join([sel[0].strip(),sel2[2].strip()]).strip())\n",
    "        l = [int(_.split(\"=\")[-1].strip()) for _ in lines[:100] if _.startswith(\"    max_degree\")]\n",
    "        f = [int(_.split(\"=\")[-1].strip()) for _ in lines[:100] if _.startswith(\"    feat\")]\n",
    "        nit = [int(_.split(\"=\")[-1].strip()) for _ in lines[:100] if _.startswith(\"    num_i\")]\n",
    "        ls.append(l)\n",
    "        fs.append(f)\n",
    "        nits.append(nit)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc756a7-d9fb-4b84-b96e-02cfa9dc54aa",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data_key, train_key = jax.random.split(\n",
    "    jax.random.PRNGKey(43), 2)\n",
    "NATOMS = 8\n",
    "files = [\"/pchem-data/meuwly/boittier/home/cf3criegee_27887.npz\"]\n",
    "train_data, valid_data = prepare_datasets(data_key, 23887, 4000,\n",
    "                                          files, \n",
    "                                          clip_esp=False, natoms=NATOMS, clean=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b974dd4a-0911-49d4-932f-4517ee349f11",
   "metadata": {},
   "source": [
    "ntest = len(valid_data[\"E\"]) // 2\n",
    "print(ntest)\n",
    "test_data = {k: v[ntest:] for k, v in valid_data.items()}\n",
    "valid_data = {k: v[:ntest] for k, v in valid_data.items()}\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a553e9-00a6-4b05-8c24-b6ff059259c5",
   "metadata": {},
   "source": [
    "model = EF(\n",
    "    # attributes\n",
    "    features = 128,\n",
    "    max_degree = 0,\n",
    "    num_iterations = 5,\n",
    "    num_basis_functions = 64,\n",
    "    cutoff = 10.0,\n",
    "    max_atomic_number = 12,\n",
    "    charges = True,\n",
    "    natoms=NATOMS,\n",
    "    total_charge=0,\n",
    "    n_res=4,\n",
    "    zbl=True,\n",
    "    # debug=[\"ele\", \"dist\", \"idx\"],\n",
    ")\n",
    "model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e717eb41-5e1f-48dc-b72a-ba6612945b2e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_keys = (\"R\", \"Z\", \"F\", \"E\", \"D\", \"N\", \"dst_idx\", \"src_idx\", \"batch_segments\")\n",
    "\n",
    "batch_size = 2000\n",
    "test_batches = prepare_batches(data_key, test_data, batch_size,\n",
    "                              num_atoms=NATOMS, \n",
    "                              data_keys=data_keys)\n",
    "\n",
    "train_batches = prepare_batches(data_key, train_data, batch_size,\n",
    "                              num_atoms=NATOMS, \n",
    "                              data_keys=data_keys)\n",
    "\n",
    "valid_batches = prepare_batches(data_key, valid_data, batch_size,\n",
    "                              num_atoms=NATOMS, \n",
    "                              data_keys=data_keys)\n",
    "\n",
    "combined = test_batches #+ valid_batches #+ train_batches\n",
    "len(combined)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59099a1c-c53b-4c44-b1d4-e108909fcff2",
   "metadata": {},
   "source": [
    "restart_dirs = [Path(\"/pchem-data/meuwly/boittier/home/pycharmm_test/ckpts/test-82ed0b7f-5f83-41d2-aba5-0a71f631fb15\")]\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31816ba3-505a-465d-9c37-dc9f99f7c6f3",
   "metadata": {},
   "source": [
    "epochs_reached = []\n",
    "\n",
    "for restart_dir in restart_dirs:\n",
    "    restart = get_last(restart_dir)\n",
    "    # print(restart.name)\n",
    "    epochs_reached.append(restart.name)\n",
    "\n",
    "epochs_reached.sort(key=lambda x: int(x.split(\"-\")[1]))\n",
    "min_epoch = epochs_reached[0]\n",
    "min_epoch\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "534be0a6-4060-42da-9b82-de5be13ad1c1",
   "metadata": {},
   "source": [
    "\n",
    "for res in restart_dirs:\n",
    "    job = f\"\"\"sbatch --export=ALL,restart={res},data=/pchem-data/meuwly/boittier/home/cf3criegee_27887.npz,name=cf3all,natoms=8,totalchg=0.0,ntrain=23887,nvalid=4000,nepochs=50000,batch_size=50,forces_w=1.0,schedule=\"warmup\" ./submit-job.sh\"\"\"\n",
    "    # os.system(job)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cce48cb-609c-4feb-9aea-fadf03afa416",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "outputs = []\n",
    "do_plot = True\n",
    "\n",
    "for restart_dir in restart_dirs:\n",
    "    # restart = restart_dir / min_epoch\n",
    "    _ = list(restart_dir.glob(\"epoch*\"))\n",
    "    _.sort(key=lambda x: abs(int(str(x.name).split(\"-\")[1])   - int(min_epoch.split(\"-\")[1])))\n",
    "    restart = _[0]\n",
    "    restart = get_last(restart_dir)\n",
    "    params,model = get_params_model(restart)\n",
    "    model.natoms = 8\n",
    "    total_params = count_params(params)\n",
    "    # print(\"Total number of parameters:\", total_params)\n",
    "    output = plot_stats(combined, model, params, _set=f\"$\\\\ell$: {model.max_degree} | mp: {model.num_iterations} | feat.: {model.features} \\n params: {total_params:.2e} | Test\", \n",
    "                   do_kde=True, batch_size=batch_size, do_plot=do_plot)\n",
    "    if do_plot:\n",
    "        plt.savefig(f\"analysis/{str(restart_dir.name)}_test.pdf\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "    outputs.append(output)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "473bd52f-c270-40b6-bb9e-a9e472706bf9",
   "metadata": {},
   "source": [
    "keys_to_compare = ['E_rmse',\n",
    " 'E_mae',\n",
    " 'F_rmse',\n",
    " 'F_mae',\n",
    " 'D_rmse',\n",
    " 'D_mae',\n",
    " 'n_params',\n",
    " 'features',\n",
    " 'max_degree',\n",
    " 'num_iterations',\n",
    " 'num_basis_functions',\n",
    " 'cutoff',\n",
    " 'max_atomic_number',\n",
    " 'natoms',\n",
    " 'total_charge',\n",
    " 'n_res']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "2c152c5c-fb97-41ef-b98b-239b90cb6302",
   "metadata": {},
   "source": [
    "results_df = pl.concat([pl.DataFrame({k:v for k,v in _.items() if k in keys_to_compare}, strict=False) for _ in outputs])\n",
    "results_df = results_df.sort(\"n_params\")\n",
    "results_df = results_df.with_columns((52.91772105638412*pl.col(\"F_rmse\") + 8*pl.col(\"E_rmse\") + 27.211386024367243*pl.col(\"D_rmse\")).alias(\"combined_rmse\"))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "273cc629-b918-4ee0-adb7-7e8f5247f528",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.set_palette(\"crest\")\n",
    "# sns.color_palette(\"Spectral\", as_cmap=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "ce541ca8-7760-4ac8-b2c8-8a3430d4211a",
   "metadata": {},
   "source": [
    "from physnetjax.tensorboard_interface import process_tensorboard_logs\n",
    "from physnetjax.plot_run import  plot_run\n",
    "import polars as pl"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "1e644b97-a809-461a-b24c-b9c31f610c72",
   "metadata": {},
   "source": [
    "results_df.sort(\"max_degree\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "ee89c55b-2e4d-4291-9587-cf6892508c6e",
   "metadata": {},
   "source": [
    "# Faster than is_pareto_efficient_simple, but less readable.\n",
    "def is_pareto_efficient(costs, return_mask = True):\n",
    "    \"\"\"\n",
    "    Find the pareto-efficient points\n",
    "    :param costs: An (n_points, n_costs) array\n",
    "    :param return_mask: True to return a mask\n",
    "    :return: An array of indices of pareto-efficient points.\n",
    "        If return_mask is True, this will be an (n_points, ) boolean array\n",
    "        Otherwise it will be a (n_efficient_points, ) integer array of indices.\n",
    "    \"\"\"\n",
    "    is_efficient = np.arange(costs.shape[0])\n",
    "    n_points = costs.shape[0]\n",
    "    next_point_index = 0  # Next index in the is_efficient array to search for\n",
    "    while next_point_index<len(costs):\n",
    "        nondominated_point_mask = np.any(costs<costs[next_point_index], axis=1)\n",
    "        nondominated_point_mask[next_point_index] = True\n",
    "        is_efficient = is_efficient[nondominated_point_mask]  # Remove dominated points\n",
    "        costs = costs[nondominated_point_mask]\n",
    "        next_point_index = np.sum(nondominated_point_mask[:next_point_index])+1\n",
    "    if return_mask:\n",
    "        is_efficient_mask = np.zeros(n_points, dtype = bool)\n",
    "        is_efficient_mask[is_efficient] = True\n",
    "        return is_efficient_mask\n",
    "    else:\n",
    "        return is_efficient\n",
    "\n",
    "def get_pareto_front(keys):\n",
    "    costs = np.array(results_df[keys])\n",
    "    pareto_front = is_pareto_efficient(costs)\n",
    "    return pareto_front\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8916860-7196-4a81-9548-10490c6342eb",
   "metadata": {
    "scrolled": true
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "3b7df759-0fc8-4d80-ae0d-7ef8e7434698",
   "metadata": {},
   "source": [
    "for i, ycol in enumerate([\"combined_rmse\"]):\n",
    "    sns.scatterplot(results_df, x=\"n_params\", y=ycol, hue=\"max_degree\", style=\"features\", size=\"num_iterations\", \n",
    "                 # markers=[m[i] for _ in range(2)]\n",
    "                    palette=\"flare\"\n",
    "                )\n",
    "\n",
    "keys = [\"n_params\", \"combined_rmse\"]\n",
    "front = get_pareto_front(keys)\n",
    "plt.plot(np.array(results_df[\"n_params\"])[front], np.array(results_df[\"combined_rmse\"])[front], color=\"gray\", alpha=0.5)\n",
    "plt.axhline(np.array(results_df[\"combined_rmse\"])[front].min(), color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "plt.axhline(np.array(results_df[\"combined_rmse\"])[front].max(), color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "plt.ylim(0)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "9dd55126-adfa-44f7-96cd-91c1d1de220e",
   "metadata": {},
   "source": [
    "for i, ycol in enumerate([\"E_rmse\"]):\n",
    "    sns.scatterplot(results_df, x=\"n_params\", y=ycol, hue=\"max_degree\", style=\"features\", size=\"num_iterations\", \n",
    "                 # markers=[m[i] for _ in range(2)]\n",
    "                    palette=\"flare\"\n",
    "                )\n",
    "plt.ylim(0)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "keys = [\"n_params\", \"E_rmse\"]\n",
    "front = get_pareto_front(keys)\n",
    "plt.plot(np.array(results_df[\"n_params\"])[front], np.array(results_df[\"E_rmse\"])[front], color=\"gray\", alpha=0.5)\n",
    "plt.axhline(np.array(results_df[\"E_rmse\"])[front].min(), color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "plt.axhline(np.array(results_df[\"E_rmse\"])[front].max(), color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "plt.show()\n",
    "\n",
    "for i, ycol in enumerate([\"F_rmse\"]):\n",
    "    sns.scatterplot(results_df, x=\"n_params\", y=ycol, hue=\"max_degree\", style=\"features\", size=\"num_iterations\", \n",
    "                 # markers=[m[i] for _ in range(2)]\n",
    "                    palette=\"flare\"\n",
    "                )\n",
    "plt.ylim(0)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "keys = [\"n_params\", \"F_rmse\"]\n",
    "front = get_pareto_front(keys)\n",
    "plt.plot(np.array(results_df[\"n_params\"])[front], np.array(results_df[\"F_rmse\"])[front], color=\"gray\", alpha=0.5)\n",
    "plt.axhline(np.array(results_df[\"F_rmse\"])[front].min(), color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "plt.axhline(np.array(results_df[\"F_rmse\"])[front].max(), color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i, ycol in enumerate([\"D_rmse\"]):\n",
    "    sns.scatterplot(results_df, x=\"n_params\", y=ycol, hue=\"max_degree\", style=\"features\", size=\"num_iterations\", \n",
    "                 # markers=[m[i] for _ in range(2)]\n",
    "                    palette=\"flare\"\n",
    "                )\n",
    "plt.ylim(0)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "keys = [\"n_params\", \"D_rmse\"]\n",
    "front = get_pareto_front(keys)\n",
    "plt.axhline(np.array(results_df[\"D_rmse\"])[front].min(), color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "plt.axhline(np.array(results_df[\"D_rmse\"])[front].max(), color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "plt.plot(np.array(results_df[\"n_params\"])[front], np.array(results_df[\"D_rmse\"])[front], color=\"gray\", alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "c402d5c4-4a8b-4df2-a7a3-95ff0fdb1fd6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dfs = [process_tensorboard_logs(Path(f.split(\"epoch-\")[0][4:] + \"tfevents/\")) for f in file_names]\n",
    "# dfs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "108f6931-bc21-4c12-9303-4cd9c05ef7e2",
   "metadata": {},
   "source": [
    "new_dfs = []\n",
    "for i in range(len(file_names)):\n",
    "    _ = dfs[i].with_columns(\n",
    "        pl.col(\"epoch\")\n",
    "        .map_elements(lambda x: ls[i][0], return_dtype=pl.Int64)\n",
    "        .alias(\"l\")\n",
    "    )\n",
    "    _ = _.with_columns(pl.col(\"epoch\").map_elements(lambda x: nits[i][0], return_dtype=pl.Int64).alias(\"nit\"))\n",
    "    new_dfs.append(_.with_columns(\n",
    "    pl.col(\"epoch\").map_elements(lambda x: fs[i][0], return_dtype=pl.Int64).alias(\"f\")))\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "b45edc81-a968-461b-b7cf-8e651e8f9e70",
   "metadata": {},
   "source": [
    "new_dfs = pl.concat(new_dfs)\n",
    "\n",
    "new_dfs = new_dfs.with_columns(\n",
    "    pl.col(\"log\")\n",
    "    .map_elements(lambda x: x.split(\"/\")[-3], return_dtype=pl.String)\n",
    "    .alias(\"uuid\")\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "56144a74-2c4a-479f-a389-306cc845e43e",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_run(base_df):\n",
    "    base_df = base_df[::10]\n",
    "    \n",
    "    # Define all the metrics to plot\n",
    "    metrics = [\n",
    "        \"train_loss\", \"valid_loss\", \n",
    "        \"train_energy_mae\", \"valid_energy_mae\", \n",
    "        \"train_forces_mae\", \"valid_forces_mae\", \n",
    "        \"lr\"\n",
    "    ]\n",
    "    \n",
    "    # Set up the plot\n",
    "    fig, ax = plt.subplots(2,4,figsize=(20, 10))\n",
    "    \n",
    "    # Plot each metric\n",
    "    for i, ycol in enumerate(metrics):\n",
    "        row = i % 2\n",
    "        col = i // 2\n",
    "        line = sns.lineplot(\n",
    "            data=base_df, \n",
    "            x=\"epoch\", y=ycol, \n",
    "            hue=\"l\", style=\"f\", size=\"nit\", \n",
    "            ax=ax[row][col], palette=\"crest\", \n",
    "            # label=ycol\n",
    "            # legend=False \n",
    "        )\n",
    "        # ax[row][col].legend()\n",
    "            # Capture lines and labels for the shared legend\n",
    "        for line_obj in line.get_lines():\n",
    "            lines.append(line_obj)\n",
    "        # labels.append(ycol)\n",
    "        \n",
    "        # Apply shared settings\n",
    "        # \n",
    "        # ax[row][col].set_xlim(1000)\n",
    "        if ycol != \"lr\":\n",
    "            ax[row][col].set_ylim(base_df[ycol].min(), base_df[ycol].median()+base_df[ycol].std())\n",
    "            ax[row][col].set_yscale(\"log\")\n",
    "        ax[row][col].set_xlabel(\"Epoch\")\n",
    "        ax[row][col].set_ylabel(ycol)\n",
    "        ax[row][col].get_legend().remove()  # Remove legend from the main plot\n",
    "    \n",
    "    # Adjust the legend on the separate axis\n",
    "    handles, labels = ax[row][col].get_legend_handles_labels()\n",
    "    ax[-1][-1].legend(\n",
    "        handles=handles, labels=labels, \n",
    "        loc='center', title=\"Metrics\"\n",
    "    )\n",
    "    ax[-1][-1].axis('off')  # Turn off axis for the legend space\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "810c0747-1cd3-4632-86cb-b0babdb04dec",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# plot_run(new_dfs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22a49cd6-ed74-4e4e-b0b2-7c04100edcb0",
   "metadata": {},
   "source": [
    "import io\n",
    "import ase\n",
    "import ase.calculators.calculator as ase_calc\n",
    "import ase.io as ase_io\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution, Stationary, ZeroRotation\n",
    "from ase.md.verlet import VelocityVerlet\n",
    "import ase.optimize as ase_opt\n",
    "import matplotlib.pyplot as plt\n",
    "import py3Dmol\n",
    "\n",
    "# Initialize atoms object and attach calculator.\n",
    "i = 1876\n",
    "print(valid_data[\"Z\"][i])\n",
    "print(valid_data['N'][i])\n",
    "Natoms = valid_data['N'][i][0] #32 #len(np.nonzero(R.sum(axis=1))[0])\n",
    "print(Natoms)\n",
    "model.natoms = Natoms\n",
    "R = valid_data['R'][i][:Natoms] # - np.mean(train_data['R'][i][:Natoms], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(R.sum(axis=1))\n",
    "print(R)\n",
    "print(valid_data['Z'][i])\n",
    "print(\"..\", (np.nonzero(R.sum(axis=-1))[0].shape[0]))\n",
    "#Natoms = np.nonzero(R.sum(axis=-1))[0].shape[0]\n",
    "print(R.shape)\n",
    "print(valid_data[\"E\"][i])\n",
    "\n",
    "\n",
    "\n",
    "atoms = ase.Atoms(valid_data['Z'][i][:Natoms], R[:Natoms] - R[:Natoms].mean(axis=0))\n",
    "print(atoms)\n",
    "model.natoms = len(atoms)\n",
    "\n",
    "@jax.jit\n",
    "def evaluate_energies_and_forces(atomic_numbers, positions, dst_idx, src_idx):\n",
    "  return model.apply(params,\n",
    "    atomic_numbers=atomic_numbers,\n",
    "    positions=positions,\n",
    "    dst_idx=dst_idx,\n",
    "    src_idx=src_idx,\n",
    "  )\n",
    "\n",
    "\n",
    "class MessagePassingCalculator(ase_calc.Calculator):\n",
    "  implemented_properties = [\"energy\", \"forces\", \"dipole\"]\n",
    "\n",
    "  def calculate(self, atoms, properties, system_changes = ase.calculators.calculator.all_changes):\n",
    "    ase_calc.Calculator.calculate(self, atoms, properties, system_changes)\n",
    "    dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(len(atoms))\n",
    "    output = evaluate_energies_and_forces(\n",
    "      atomic_numbers=atoms.get_atomic_numbers(),\n",
    "      positions=atoms.get_positions(),\n",
    "      dst_idx=dst_idx,\n",
    "      src_idx=src_idx\n",
    "    )\n",
    "\n",
    "    dipole = dipole_calc(atoms.get_positions(), \n",
    "                         atoms.get_atomic_numbers(), \n",
    "                         output[\"charges\"],\n",
    "                np.zeros_like(atoms.get_atomic_numbers()),\n",
    "                1)\n",
    "    self.results[\"dipole\"] = dipole\n",
    "    self.results['energy'] = output[\"energy\"].squeeze() #* (ase.units.kcal/ase.units.mol)\n",
    "    self.results['forces'] = output[\"forces\"] #* (ase.units.kcal/ase.units.mol) #/ase.units.Angstrom"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0b7af04-5cef-40e2-a957-0497258dc3c9",
   "metadata": {},
   "source": [
    "# if True:\n",
    "#     from pathlib import Path\n",
    "#     restart_dir_base = Path(\"/pchem-data/meuwly/boittier/home/pycharmm_test/ckpts/\")\n",
    "#     restart_dir = restart_dir_base / \"test-ef20ef7e-f086-428c-867e-c7f631eead87\"\n",
    "    \n",
    "#     # restart_dir = restart_dir_base / \"test-8eaea815-24ac-43e9-9efd-177d7101c2c5\"\n",
    "    \n",
    "#     from training import get_last, get_files, get_params_model\n",
    "#     restart = get_last(restart_dir)\n",
    "#     dirs = get_files(restart_dir)\n",
    "#     # for _ in test_batches[0].keys():\n",
    "#     #     print(_, test_batches[0][_].shape)\n",
    "        \n",
    "#     params,model = get_params_model(restart)\n",
    "# valid_batches['N'][:100]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3dc1d-f9da-4b47-ac62-210e4b666085",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4ed4316-dd2f-472b-bf59-143e5c5bfc60",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "atoms.set_calculator(MessagePassingCalculator())\n",
    "\n",
    "# Write structure to xyz file.\n",
    "xyz = io.StringIO()\n",
    "ase_io.write(xyz, atoms, format='xyz')\n",
    "\n",
    "# Visualize the structure with py3Dmol.\n",
    "view = py3Dmol.view()\n",
    "view.addModel(xyz.getvalue(), 'xyz')\n",
    "view.setStyle({'stick': {'radius': 0.15}, 'sphere': {'scale': 0.25}})\n",
    "view.show()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "876d15a7-48ca-4d85-931b-66bb3726d2ad",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Run structure optimization with BFGS.\n",
    "_ = ase_opt.BFGS(atoms).run(fmax=0.001,steps=100)\n",
    "print()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fda0800-3ff0-40ae-94d4-396823138042",
   "metadata": {},
   "source": [
    "print(atoms.get_dipole_moment())\n",
    "# Write structure to xyz file.\n",
    "xyz = io.StringIO()\n",
    "ase_io.write(xyz, atoms, format='xyz')\n",
    "# Visualize the structure with py3Dmol.\n",
    "view = py3Dmol.view()\n",
    "view.addModel(xyz.getvalue(), 'xyz')\n",
    "view.setStyle({'stick': {'radius': 0.15}, 'sphere': {'scale': 0.25}})\n",
    "view.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4a78b28-6112-4aff-aa98-de4ffcbb1644",
   "metadata": {},
   "source": [
    "# Parameters.\n",
    "temperature = 1000\n",
    "timestep_fs = 0.5\n",
    "num_steps = 10_000\n",
    "\n",
    "# Draw initial momenta.\n",
    "MaxwellBoltzmannDistribution(atoms, temperature_K=temperature)\n",
    "Stationary(atoms)  # Remove center of mass translation.\n",
    "ZeroRotation(atoms)  # Remove rotations.\n",
    "\n",
    "# Initialize Velocity Verlet integrator.\n",
    "integrator = VelocityVerlet(atoms, timestep=timestep_fs*ase.units.fs)\n",
    "\n",
    "# Run molecular dynamics.\n",
    "frames = np.zeros((num_steps, len(atoms), 3))\n",
    "dipoles = np.zeros((num_steps, 1, 3))\n",
    "potential_energy = np.zeros((num_steps,))\n",
    "kinetic_energy = np.zeros((num_steps,))\n",
    "total_energy = np.zeros((num_steps,))\n",
    "for i in range(num_steps):\n",
    "  # Run 1 time step.\n",
    "  integrator.run(1)\n",
    "  # Save current frame and keep track of energies.\n",
    "  frames[i] = atoms.get_positions()\n",
    "  potential_energy[i] = atoms.get_potential_energy()\n",
    "  kinetic_energy[i] = atoms.get_kinetic_energy()\n",
    "  total_energy[i] = atoms.get_total_energy()\n",
    "  dipoles[i]=atoms.get_dipole_moment()\n",
    "  # Occasionally print progress.q\n",
    "  if i % 1000 == 0:\n",
    "    print(f\"step {i:5d} epot {potential_energy[i]: 5.3f} ekin {kinetic_energy[i]: 5.3f} etot {total_energy[i]: 5.3f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "beebd7dc-8f5e-4c21-9bb9-57642506a213",
   "metadata": {},
   "source": [
    "view.getModel().setCoordinates(frames[::10], 'array')\n",
    "view.animate({'loop': None, 'interval': 0.1})\n",
    "view.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "249cafa6-0abc-417e-ba97-ee497f4e7966",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "plt.xlabel('time [fs]')\n",
    "plt.ylabel('energy [eV]')\n",
    "time = np.arange(num_steps) * timestep_fs\n",
    "plt.plot(time, potential_energy, label='potential energy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(time, kinetic_energy, label='kinetic energy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(time, total_energy - total_energy.mean(), label='total energy')\n",
    "plt.legend()\n",
    "plt.ylim(-23/1000, 23/1000)\n",
    "plt.xlabel('time [fs]')\n",
    "plt.ylabel('energy [eV]')\n",
    "plt.grid()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0b4f5ba-9dfc-4158-90d4-6d0beb870d0a",
   "metadata": {},
   "source": [
    "r = dipoles\n",
    "# for i in range(3):\n",
    "\n",
    "plt.plot(np.linalg.norm(r,axis=-1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80a4caaa-9fc6-4b0a-b14e-ce7d145057f2",
   "metadata": {},
   "source": [
    "from physnetjax.ir import autocorrelation_ft, intensity_correction, rolling_avg\n",
    "freq, spectra = autocorrelation_ft(dipoles.squeeze(), timestep_fs * 0.001 )\n",
    "freq, spectra = intensity_correction(freq, spectra, 1000000000000000)\n",
    "freq, spectra = rolling_avg(freq, spectra)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4170d76-1bb1-4019-8686-adc97c108958",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.plot(freq, spectra)\n",
    "# plt.ylim(0,0.2)\n",
    "plt.xlim(1, 4000)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab813941-61d4-4160-bbc9-1624597932d7",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa829bc-7d8b-448e-af68-2fba1e85b9b1",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physnetjax",
   "language": "python",
   "name": "jaxphyscharmm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
